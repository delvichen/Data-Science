{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-KNN adalah model machine learning yang dapat digunakan untuk melakukan prediksi berdasarkan kedekatan karakteristik dengan sejumlah tetangga terdekat.\n",
    "\n",
    "-Prediksi yang dilakukan dapat diterapkan baik pada classification maupun regression tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check referensi di https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sensus = {'tinggi': [158, 170, 183, 191, 155, 163, 180, 158, 170], \n",
    "          'jk': ['pria', 'pria', 'pria', 'pria', 'wanita', 'wanita', 'wanita', 'wanita', 'wanita'],\n",
    "          'berat': [64, 86, 84, 80, 49, 59, 67, 54, 67]}\n",
    "\n",
    "sensus_df = pd.DataFrame(sensus)\n",
    "sensus_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sesi Pembelajaran ini membentuk dataset yang sama dengan pembelajarannya sebelumnya yaitu memprediksi berat badan berdasarkan data tinggi badan dan jenis kelamin\n",
    "\n",
    "* Tinggi dan jenis kelamin berperan sebagai features.\n",
    "* Berat badan sebagai berperan target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression dengan KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features & Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.array(sensus_df[['tinggi', 'jk']]) # sekumpulan nilai features untuk training set\n",
    "y_train = np.array(sensus_df['berat']) # sekumpulan nilai target untuk training set\n",
    "\n",
    "print(f'X_train:\\n{X_train}\\n')\n",
    "print(f'y_train: {y_train}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Memanfaatkan KNN untuk melakukan estimasi berdasarkan data tinggi badan dan jenis kelaminnya,karena nilai yang diprediksi berupa nilai continuous dan bukan category seperti sesi pembelajaran sebelumnya, maka kasus ini termasuk dalam regression tasks.\n",
    "\n",
    "* Pada sesi pembelajaran sebelumnya,kita sudah memahami KNN akan melakukan prediksi berdasarkan sejumlah tetangga terdekat, di mana tetangga terdekat ini ditentukan berdasarkan kalkulasi jarak dengan memanfaatkan Euclidean Distance. Disini tentunya kita perlu memastikan nilai featuresnya bertipe data numerik supaya dapat dihitung jarak antar data pointnya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Dataset: Konversi Label menjadi Numerik Biner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transposed = np.transpose(X_train)\n",
    "\n",
    "print(f'X_train:\\n{X_train}\\n')\n",
    "print(f'X_train_transposed:\\n{X_train_transposed}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Proses transpose ini pada dasarnya akan mengubah posisi baris menjadi kolom dan posisi kolom menjadi baris.\n",
    "* Posisi baris di atas mengindikasikan instance sedangkan posisi kolomnya mengindikasikan features.\n",
    "* Kasus ini Mengubah posisi features menjadi baris dan bukan kolom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "jk_binarised = lb.fit_transform(X_train_transposed[1])\n",
    "\n",
    "print(f'jk: {X_train_transposed[1]}\\n')\n",
    "print(f'jk_binarised:\\n{jk_binarised}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pada sesi pembelajaran sebelumnya kita sudah membahas LabelBinarizer,LabelBinarizer digunakan untuk mengkonversikan nilai pria dan wanita menjadi nilai biner 0 dan 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jk_binarised = jk_binarised.flatten()\n",
    "jk_binarised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method Flatten() digunakan untuk mengkonversikan multi dimensional array menjadi single dimensional array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transposed[1] = jk_binarised\n",
    "X_train = X_train_transposed.transpose()\n",
    "\n",
    "print(f'X_train_transposed:\\n{X_train_transposed}\\n')\n",
    "print(f'X_train:\\n{X_train}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train akan kita transpose balik agar yang tadinya baris kembali menjadi kolom dan yang tadinya kolom menjadi baris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training KNN Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "K = 3 \n",
    "model = KNeighborsRegressor(n_neighbors=K)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"K\" akan berkolerasi dengan jumlah/banyaknya tetangga yang akan digunakan untuk proses prediksi\n",
    "\n",
    "*Model machine learning yang digunakan untuk regression tasks sering kali dikenal dengan istilah \"Regressor\" sedangkan model machine learning yang digunakan untuk classification tasks sering kali dikenal dengan istilah \"Classifier\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediksi Berat Badan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array([[155, 1]])\n",
    "X_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Melakukan prediksi berat badan berdasarkan tinggi badan dan jenis kelamin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Melakukan prediksi berat badan dengan memanfaatkan model KNN Regressor yang sudah di training sebelumnya\n",
    "* Data Diprediksi dengan tinggi badan 155 dan jenis kelamin wanita memiliki berat badan 55.66666667"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluasi KNN Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disini mempelajari beberapa metrics yang bisa kita gunakan untuk mengukur performa dari model machine learning untuk kasus regression tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array([[168, 0], [180, 0], [160, 1], [169, 1]])\n",
    "y_test = np.array([65, 96, 52, 67])\n",
    "\n",
    "print(f'X_test:\\n{X_test}\\n')\n",
    "print(f'y_test: {y_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baris Pertama : Menyiapkan 4 instances atau data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasilnya bahwa data dengan tinggi badan 168 dan jenis kelamin \"pria\",ini diprediksi memilki berat badan \"70.66666667\" sedangkan data yang yang diharapkan adalah \"65\"\n",
    "\n",
    "Data point akhir dengan tinggi badan 169 dan jenis kelamin \"wanita\",ini diprediksi memilki berat badan \"70.66666667\" sedangkan data yang yang diharapkan adalah \"67\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coefficient of Determination atau $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check referensi di https://en.wikipedia.org/wiki/Coefficient_of_determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'R-squared: {r_squared}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-squared semakin dia mendekati 1 maka semakin baik dan semakin dia mendekati 0 atau bahkan ketika nilainya negatif ini mengindikasikan model yang kurang baik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Absolute Error (MAE) atau Mean Absolute Deviation (MAD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$MAE$ is the average of the absolute values of the errors of the predictions.\n",
    "\n",
    "*$MAE$ merupakan nilai rata-rata dari absolute error dari prediksi*\n",
    "\n",
    "$MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAE akan menghitung selisih atau error antara ùë¶ùëñ dan ùë¶ÃÇùëñ\n",
    "*ùë¶ùëñ mempresentasikan setiap nilai target pada testing set*\n",
    "*ùë¶ÃÇùëñ merupakan nilai prediksi yang dihasilkan oleh model kita*\n",
    "\n",
    "* Proses perhitungan selisih ini memungkinkan hasil nilai positif ataupun negatif, jika nilai yang diprediksi lebih kecil dari apa yang seharusnya maka nilainya positif tetapi kalau hasil prediksi ternyata lebih besar dari nilai yang semestinya maka nilainya menjadi negatif.\n",
    "* Untuk menghindari nilai negatif maka kita menerapkan \"absolute function\",\"absolute function\" ini akan menghilangkan nilai negatif (-2 menjadi 2)\n",
    "* Setiap selisih nilai ini akan diakumulasi untuk berikutnya kita bagi dengan 'ùëõ' ,'ùëõ' mempresentasikan jumlah data pointnya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check referensi di https://en.wikipedia.org/wiki/Mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f'MAE: {MAE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Semakin kecil nilai MAE akan mengindikasikan kualitas model yang makin/lebih baik*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Squared Error (MSE) atau Mean Squared Deviation (MSD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$MSE$ is the average of the squares of the errors of the predictions.\n",
    "\n",
    "*$MSE$ merupakan rata-rata dari error kuadrat untuk prediksi*\n",
    "\n",
    "$MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE akan menghitung selisih atau error antara ùë¶ùëñ dan ùë¶ÃÇùëñ\n",
    "*ùë¶ùëñ mempresentasikan setiap nilai target pada testing set*\n",
    "*ùë¶ÃÇùëñ merupakan nilai estimasi yang dihasilkan oleh model kita*\n",
    "\n",
    "* Proses perhitungan selisih ini memungkinkan hasil nilai positif ataupun negatif, jika nilai yang diprediksi lebih kecil dari apa yang seharusnya maka nilainya positif tetapi kalau hasil prediksi ternyata lebih besar dari nilai yang semestinya maka nilainya menjadi negatif.\n",
    "* Untuk menghindari nilai negatif pada MSE,selisih nilainya dipangkatkan dua\n",
    "* Setiap selisih nilai ini akan diakumulasi untuk berikutnya kita bagi dengan 'ùëõ' ,'ùëõ' mempresentasikan jumlah data pointnya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check referensi di https://en.wikipedia.org/wiki/Mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'MSE: {MSE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semakin kecil nilai MSE akan mengindikasikan kualitas model yang makin/lebih baik\n",
    "\n",
    "*Nilai MSE akan selalu lebih besar bila dibandingkan dengan nilai MAE karena setiap nilai errornya untuk MSE akan dipangkatkan dua*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permasalahan Scaling pada Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada slide ini akan mempelajari apa dampak dari perbedaan satuan pengukuran terhadap konsistensi hasil kalkulasi Euclidean Distancenya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# tinggi dalam milimeter\n",
    "X_train = np.array([[1700, 0], [1600, 1]]) #berisi sekumpulan nilai features untuk training set\n",
    "X_new = np.array([[1640, 0]]) ##berisi sekumpulan features untuk data point yang akan kita prediksi\n",
    "\n",
    "[euclidean(X_new[0], d) for d in X_train] # mengukur jarak untuk data point yang baru ini terhadap kedua data point training setnya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hasil yang pertama merupakan jarak antara data point yang baru ini terhadap data point pertama pada training set dan Hasil yang kedua merupakan jarak antara data point yang baru terhadap data point kedua pada training set\n",
    "* Pada eksperimen pertama ini nampak jelas bahwa data point yang baru lebih dekat dengan data point kedua bila dibandingkan dengan data point pertama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tinggi dalam meter\n",
    "X_train = np.array([[1.7, 0], [1.6, 1]])\n",
    "X_new = np.array([[1.64, 0]])\n",
    "\n",
    "[euclidean(X_new[0], d) for d in X_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sama halnya dengan milimeter,Hasil yang pertama merupakan jarak antara data point yang baru ini terhadap data point pertama pada training set dan Hasil yang kedua merupakan jarak antara data point yang baru terhadap data point kedua pada training set\n",
    "* Pada eksperimen kedua ini nampak jelas bahwa data point yang baru lebih dekat dengan data point pertama bila dibandingkan dengan data point kedua\n",
    "* Menemui ketidakkonsistenan dalam pengukuran jarak (metode yang digunakan untuk mengatasi permasalah ini adalah menerapkan \"Standard Scaler\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menerapkan Standard Scaler (Standard Score atau Z-Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize features by removing the mean and scaling to unit variance.\n",
    "\n",
    "$z = \\frac{x - \\bar{x}}{S}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ùë• mempresentasikan nilai features\n",
    "* xÃÑ mempresentasikan rata-rata nilai features nya\n",
    "* ùëÜ mempresentasikan standard deviation dari sekumpulan nilai features tersebut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check referensi di https://en.wikipedia.org/wiki/Standard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tinggi dalam milimeter\n",
    "X_train = np.array([[1700, 0], [1600, 1]])\n",
    "X_train_scaled = ss.fit_transform(X_train) #b2\n",
    "print(f'X_train_scaled:\\n{X_train_scaled}\\n')\n",
    "\n",
    "X_new = np.array([[1640, 0]])\n",
    "X_new_scaled = ss.transform(X_new) #b5\n",
    "print(f'X_new_scaled: {X_new_scaled}\\n')\n",
    "\n",
    "jarak = [euclidean(X_new_scaled[0], d) for d in X_train_scaled]\n",
    "print(f'jarak: {jarak}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Baris Kedua : Mengenakan Standard scaled pada nilai X_train nya\n",
    "* Baris Kelima : Proses tranformasinya langsung panggil \"transform\" tidak panggil lagi fit_transfortm, karena proses fitnya akan dikenakan pada X_train tetapi proses transformnya akan dikenakan baik pada X_train maupun pada X_new\n",
    "* Nilai-nilai Tidak menggunakan satuan centimeter atau milimeter ataupun meter tetapi menggunakan satuan standard score\n",
    "* 1.2 adalah jarak antara X_new_scaled dengan X_train_scaled untuk data point pertama sedangkan 2.1540659228538015 merupakan jarak X_new_scaled dengan data point kedua pada X_train_scaled\n",
    "* Pada eksperimen ini nampak jelas bahwa data point yang baru lebih dekat dengan data point pertama bila dibandingkan dengan data point kedua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tinggi dalam meter\n",
    "X_train = np.array([[1.7, 0], [1.6, 1]])\n",
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "print(f'X_train_scaled:\\n{X_train_scaled}\\n')\n",
    "\n",
    "X_new = np.array([[1.64, 0]])\n",
    "X_new_scaled = ss.transform(X_new)\n",
    "print(f'X_new_scaled: {X_new_scaled}\\n')\n",
    "\n",
    "jarak = [euclidean(X_new_scaled[0], d) for d in X_train_scaled]\n",
    "print(f'jarak: {jarak}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1.2000000000000026 merupakan jarak antara X_new_scaled dengan data point pertama pada X_train_scaled sedangkan 2.1540659228538006 merupakan jarak antara X_new_scaled dengan data point kedua pada X_train_scaled\n",
    "* Pada eksperimen ini nmenghasilkan nilai jarak yang sama atau setidaknya sangat mendekati dengan nilai jarak pada eksperimen pertama,disini juga bisa tampak bahwa data point yang baru juga lebih dekat dengan data point pertama bila dibandingkan dengan data point kedua"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menerapkan Features Scaling pada KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada slide ini kita akan ulangi lagi proses training dan evaluasi model KNN yang pernah kita lakukan sebelumnya tetapi kali ini kita akan menerapkan \"Features Scaling\",\"Features Scaling\" yang akan digunakan adalah $Standard Scaler$.kita akan lihat bagaimana features scaling ini berpotensi dalam meningkatkan performa dari model KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set\n",
    "X_train = np.array([[158, 0], [170, 0], [183, 0], [191, 0], [155, 1], [163, 1],\n",
    "                    [180, 1], [158, 1], [170, 1]])\n",
    "\n",
    "y_train = np.array([64, 86, 84, 80, 49, 59, 67, 54, 67])\n",
    "\n",
    "# Test Set\n",
    "X_test = np.array([[168, 0], [180, 0], [160, 1], [169, 1]])\n",
    "y_test = np.array([65, 96, 52, 67])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training dan Testing set yang kita gunakan ini sama persis dengan Training dan Testing set yang kita gunakan sebelumnya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features Scaling (Standard Scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yang berbeda disini adalah Training dan Testing setnya tersedia kita tidak langsung melakukan proses training model.tetapi pertama-tama kita akan scalling dulu featuresnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "X_test_scaled = ss.transform(X_test)\n",
    "\n",
    "print(f'X_train_scaled:\\n{X_train_scaled}\\n')\n",
    "print(f'X_test_scaled:\\n{X_test_scaled}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training & Evaluasi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_scaled, y_train) #features yang sudah kita scalling\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'MAE: {MAE}')\n",
    "print(f'MSE: {MSE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perbandigan Hasil MAE dan MSE setelah menerapkan features scaling hasilnya lebih kecil atau dengan kata lain kta bisa menghasilkan model dengan kualitas atau performa yang lebih setelah menerapkan features scaling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
